{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho disciplina de Introdução à Teoria da Computação\n",
    "### Geração de Comentários Falsos do Mercado Livre utilizando Cadeias de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonathan Daniel Ramos - 10857082\n",
    "\n",
    "Daniel de Jesus Lima - 10723951\n",
    "\n",
    "Matheus Aquati Kurianski - 10687541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, é necessário que limpemos nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "with open('comments.txt') as f:\n",
    "    comments = f.read()\n",
    "\n",
    "pontuations = ['.','-',',','!','?','(','—',')']\n",
    "first_words = []\n",
    "end_words = []\n",
    "\n",
    "# Aqui decidimos pegar todas as palavras que iniciam os comentários extraídos, de modo a torná-las estados inicias no nosso automato\n",
    "for word_begin in re.findall(r'\\n\\w+\\b', comments): \n",
    "    word_begin = word_begin.replace('\\n', '')\n",
    "    first_words.append(word_begin)\n",
    "\n",
    "# Removendo caracteres especiais para o texto ficar um pouquinho menos poluído\n",
    "comments = comments.replace('\\t',' ')\n",
    "comments = comments.replace('“', ' ')\n",
    "comments = comments.replace('”', ' ')\n",
    "comments = comments.replace('\"', ' ')\n",
    "\n",
    "# Muitas pontuações estão coladas às palavras, e aqui descolamos a fim de serem consideradas palavras\n",
    "for pontuation in pontuations:\n",
    "    comments = comments.replace(pontuation, ' {0} '.format(pontuation))\n",
    "\n",
    "# Para ficar mais emocionante, decidimos ignorar comentários muito pequenos\n",
    "# Além disso, aqui já pegamos as palavras que encerram os comentários (exceto pontuações) a fim de torna-las estados finais\n",
    "for line in comments.split('\\n'):\n",
    "    words = line.split(' ')\n",
    "    if len(words) < 6:\n",
    "        continue\n",
    "    for word in reversed(words):\n",
    "        if word == '' or word in pontuations:\n",
    "            continue\n",
    "        end_words.append(word)\n",
    "        break\n",
    "\n",
    "# Torna tudo uma linha só tirando as quebras de linha. Não é interessante pro algoritmo que pensamos que haja quebra de linhas, então simplesmente a removemos\n",
    "comments = comments.replace('\\n', ' ')\n",
    "\n",
    "# Dados prontos para usar\n",
    "comments = comments.split()\n",
    "first_words = np.array(first_words)\n",
    "end_words = np.array(end_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui basicamente mapeamentos cada palavra X de modo que sabemos quantas vezes uma palavra Y apareceu seguida de X.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "\"Eu gosto de Cachorro\"\n",
    "\n",
    "\"Eu gosto de Gato\"\n",
    "\n",
    "Assim, contamos que \"gosto\" apareceu seguida de \"Eu\" 2 vezes, enquanto \"Cachorro\" e \"Gato\" apareceram seguidos de \"de\" uma vez cada\n",
    "\n",
    "Será útil para estimar as probabilidades de chegar a alguma palavra a partir de outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = {}\n",
    "\n",
    "for i, word in enumerate(comments[1:]):\n",
    "    previous_word = comments[i-1].lower()\n",
    "    word = word.lower()\n",
    "    \n",
    "    if previous_word not in word_pairs:\n",
    "        word_pairs[previous_word] = {}\n",
    "    if word in word_pairs[previous_word]:\n",
    "        word_pairs[previous_word][word] += 1\n",
    "    else:    \n",
    "        word_pairs[previous_word][word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora basta construírmos nosso modelo:\n",
    "\n",
    "Da forma que fizemos, há um parâmetro para escolhermos o número de palavras. Se esse parâmetro não for preenchido (ou seja, valor default fica como -1), ele vai continuar gerando palavras até chegar no estado final, sendo que usamos uma condição extra para que as frases ficassem um pouco mais longas, que é caso chegue num estado final ele tem 50% de chance de parar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(first_word, total_words=-1):\n",
    "    sentence = first_word.capitalize()\n",
    "    current_word = first_word.lower()\n",
    "    if total_words <= -1:\n",
    "        total_words = 50\n",
    "        stop_word = True\n",
    "    else:\n",
    "        stop_word = False\n",
    "    \n",
    "    for i in range(total_words):\n",
    "        current_word_pairs = word_pairs[current_word]\n",
    "        total = sum(current_word_pairs.values())\n",
    "        if(total == 0): continue\n",
    "        \n",
    "        next_word = []\n",
    "        weight = []\n",
    "        for key, word in current_word_pairs.items():\n",
    "            next_word.append(key)\n",
    "            weight.append(word/total)\n",
    "        next_word = np.array(next_word)\n",
    "        weight = np.array(weight)\n",
    "        \n",
    "        chosen_word = np.random.choice(next_word, p=weight).strip() # Esse strip é semelhante ao \"trim()\" em algumas linguagens. Basicamente remove espaços em branco nas extremidades de uma String\n",
    "        if chosen_word in pontuations:\n",
    "            sentence += chosen_word\n",
    "        elif current_word in ['.', '?'] or chosen_word == 'i':\n",
    "            sentence += \" \" + chosen_word.capitalize()\n",
    "        else:\n",
    "            sentence += \" \" + chosen_word\n",
    "        if stop_word and chosen_word in end_words:\n",
    "            if np.random.rand() > 0.5: \n",
    "                break\n",
    "        current_word = chosen_word\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obter alguns resultados inserindo algumas palavras que servem de estados iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uma alternativa fora ótimo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feliz!!! parabéns ótimo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Melhor benefício bom recomendo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Continuem. Que, e áudio incrível os ficam. Forro fundo etc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'A. Sei estrelas'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Produto ótima amei'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Produto parabéns produto muito mesmo essa um, tamanho'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Material som. Bom'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Otimo bonito'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Exatamente anunciado'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_first_words = np.random.choice(first_words, (10,))\n",
    "random_first_words\n",
    "\n",
    "for random_first_word in random_first_words:\n",
    "    display(markov_chain(random_first_word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
